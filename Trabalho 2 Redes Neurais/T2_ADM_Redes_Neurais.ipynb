{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T2 ADM Redes Neurais",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "3sMkuIQWHCaM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "bdd5aba4-2f0a-488a-f068-c00fbd2a52f1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529552744529,
          "user_tz": 180,
          "elapsed": 6775,
          "user": {
            "displayName": "Augusto Bennemann",
            "photoUrl": "//lh4.googleusercontent.com/-uh1jffP4anU/AAAAAAAAAAI/AAAAAAAAA88/1TQ_-mFOf34/s50-c-k-no/photo.jpg",
            "userId": "110926773250512152064"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "# Display file input on Google Colab\n",
        "try:\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "except ImportError:\n",
        "  pass"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-56bbd585-80d4-472e-a708-c98d11b61505\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-56bbd585-80d4-472e-a708-c98d11b61505\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving wine_with_names.csv to wine_with_names.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N5VtoBFeY1BF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "DEBUG = False\n",
        "\n",
        "def log(s):\n",
        "  if DEBUG:\n",
        "    print(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2jOHuDJ9cDJo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import operator\n",
        "import copy\n",
        "\n",
        "KFOLDS = 10\n",
        "\n",
        "original_dataset = None\n",
        "preditiveAttributes = {}\n",
        "allAttributes = {}\n",
        "EXPECTED_COLUMN = \"\"\n",
        "dataset = None\n",
        "np_original_dataset = None\n",
        "possibleClasses = {}\n",
        "\n",
        "\n",
        "def openFile(filename, delimiter):\n",
        "  with open(filename, 'r') as file:\n",
        "    global preditiveAttributes, allAttributes, original_dataset, EXPECTED_COLUMN\n",
        "    lines = csv.reader(file, delimiter=delimiter)\n",
        "    list_lines = list(lines)\n",
        "\n",
        "    preditiveAttributes = {x:i for i,x in enumerate(list_lines[0][:-1])}\n",
        "    allAttributes = {x:i for i,x in enumerate(list_lines[0])} #Includes Class (last column)\n",
        "\n",
        "    original_dataset = list_lines[1:]\n",
        "    #EXPECTED_COLUMN = -1 #list_lines[0][-1]\n",
        "    \n",
        "\"\"\"\n",
        "ATENCAO: \n",
        "  (i) a classe a ser prevista deve ser a ultima coluna do dataset\n",
        "  (ii) a primeira linha deve conter o nome de cada atributo\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def countClasses(dataset, attribute_index=EXPECTED_COLUMN):\n",
        "  frequency = {} # frequency of a value\n",
        "  \n",
        "  for line in dataset:\n",
        "    if line[attribute_index] in frequency:\n",
        "      frequency[line[attribute_index]] += 1.0\n",
        "    else:\n",
        "      frequency[line[attribute_index]] = 1.0\n",
        "      \n",
        "  return frequency\n",
        "      \n",
        "\n",
        "def generatePossibleClasses(original_dataset):\n",
        "  # Converte classes possiveis (string) para números e fornece função pra consultá-las\n",
        "  countclasses = countClasses(original_dataset, -1)\n",
        "  possibleClasses = {}\n",
        "  for possibleClass in countclasses:\n",
        "    if not possibleClass in possibleClasses:\n",
        "      possibleClasses[possibleClass] = len(possibleClasses)\n",
        "  return possibleClasses\n",
        "\n",
        "def normalize_data(dataset, high=1.0, low=0.0):\n",
        "    mins = np.min(dataset, axis=0)\n",
        "    maxs = np.max(dataset, axis=0)\n",
        "    \n",
        "    rng = maxs - mins\n",
        "    for i,d in enumerate(rng):\n",
        "      if d == 0:\n",
        "        rng[i] = 0.0000001 # avoid division by zero\n",
        "      \n",
        "    return high - (((high - low) * (maxs - dataset)) / rng)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yG_NqYNL51EU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def printFloatPrecision5(l):\n",
        "  return \"  \".join(\"%.5f\" % a for a in l)\n",
        "\n",
        "def twoDimensionPrintFloatPrecision5(l, preffix):\n",
        "  msg = preffix\n",
        "  for l2 in l:\n",
        "    msg += \" \".join(\"%.5f\" % a for a in l2)\n",
        "    msg += \"\\n\"\n",
        "    msg += preffix\n",
        "  return msg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5_kEE-esHFas",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class Neuron:\n",
        "  delta = 0\n",
        "  activation = 0\n",
        "  weights = []\n",
        "  \n",
        "  def __init__(self, initialWeights):\n",
        "    self.weights = initialWeights\n",
        "    self.delta = 0\n",
        "    self.activation = 0\n",
        " \n",
        "  def setDelta(self, delta):\n",
        "    self.delta = delta\n",
        "    \n",
        "  def getDelta(self):\n",
        "    return self.delta\n",
        "  \n",
        "  def __str__(self):\n",
        "    return \"  \".join(\"%.5f\" % w for w in self.weights)\n",
        "    \n",
        "class Layer:\n",
        "  neurons = []\n",
        "  \n",
        "  def __init__(self, weights):\n",
        "    self.neurons = []\n",
        "    for w in weights:\n",
        "      self.neurons.append(Neuron(w))\n",
        "    \n",
        "  def __str__(self):    \n",
        "    msg = \"\"\n",
        "    for i, n in enumerate(self.neurons):\n",
        "      msg += \"\\t%s\\n\" % n\n",
        "    return msg\n",
        "  \n",
        "class Network:\n",
        "  regularizationFactor = 0\n",
        "  alpha = 0\n",
        "  layers = []\n",
        "  \n",
        "  def __init__(self, regularizationFactor, layersWeights, inputSize, alpha=0.0001):\n",
        "    print(\"Inicializando rede com a seguinte estrutura de neuronios por camadas: [%d %s]\" % (inputSize, \" \".join(\"%d\" % len(a) for a in layersWeights)))\n",
        "    \n",
        "    self.regularizationFactor = regularizationFactor\n",
        "    self.alpha = alpha\n",
        "    self.layers = []\n",
        "    for lw in layersWeights:\n",
        "      self.layers.append(Layer(lw))\n",
        "    \n",
        "  def __str__(self):\n",
        "    msg = \"Parametro de regularizacao lambda=%.3f\\n\" % self.regularizationFactor\n",
        "    for i, l in enumerate(self.layers):\n",
        "      msg += (\"\\nTheta%d inicial (pesos de cada neuronio, incluindo bias, armazenados nas linhas):\\n\" % (i+1))\n",
        "      msg += str(l)\n",
        "    return msg\n",
        "  \n",
        "  def activationFunction(self, x):\n",
        "    return (1 / (1 + math.exp(-x)))\n",
        "  \n",
        "  def derivativeFunction(self, output):\n",
        "    return output*(1.0-output)\n",
        "    \n",
        "  def updateWeights(self, gradients, J):\n",
        "    log(\"\\n ---> Atualizando os pesos <--- \\n\")\n",
        "    for l, layer in enumerate(self.layers):\n",
        "      for n, neuron in enumerate(layer.neurons):\n",
        "        neuron.weights = list(np.array(neuron.weights) - self.alpha * J * np.array(gradients[l][n]))\n",
        "\n",
        "  def calculateNetworkError2(self, instances):\n",
        "    log(\"Calculando erro/custo J deste mini-batch\")\n",
        "    J = 0\n",
        "\n",
        "    for i, d in enumerate(instances):\n",
        "      log(\"\\tProcessando exemplo de treinamento %d do mini-batch\" % (i+1))\n",
        "\n",
        "      inputPrecision5 = printFloatPrecision5(d['attributes'])\n",
        "      expectedPrecision5 = printFloatPrecision5(d['expected'])\n",
        "\n",
        "      log(\"\\tPropagando entrada [%s]\" % inputPrecision5)\n",
        "\n",
        "      input = np.array([1] + d['attributes']) # [1] is for bias\n",
        "\n",
        "      all_activations = []\n",
        "\n",
        "      for k, layer in enumerate(self.layers):\n",
        "        layer_activations =[]\n",
        "        prevInput = np.array([1])\n",
        "        results = []\n",
        "        log(\"\\t\\ta%d: [%s]\\n\" % (k+1, printFloatPrecision5(input)))\n",
        "        for neuron in layer.neurons:\n",
        "          weights = np.array(neuron.weights)\n",
        "          result = weights.T.dot(input)\n",
        "          activation = self.activationFunction(result)\n",
        "\n",
        "          layer_activations.append(activation)\n",
        "\n",
        "          results.append(result)\n",
        "          prevInput = np.append(prevInput, activation)        \n",
        "\n",
        "        log(\"\\t\\tz%d: [%s]\" % (k+2, printFloatPrecision5(results)))\n",
        "\n",
        "        input = prevInput\n",
        "\n",
        "        all_activations.append(layer_activations)\n",
        "\n",
        "      d[\"results\"] = np.round(input[1:], 5)\n",
        "\n",
        "      d[\"activations\"] = all_activations\n",
        "\n",
        "      outputPrecision5 = printFloatPrecision5(input[1:]) # ignores first element (bias)\n",
        "      log(\"\\t\\ta%d: [%s]\\n\" % (len(self.layers)+1, outputPrecision5)) # TODO meio gambiarra isso, mas senao não aparece o ultimo 'a'\n",
        "      log(\"\\t\\tf(x): [%s]\" % (outputPrecision5))\n",
        "\n",
        "      log(\"\\tSaida predita para o exemplo %d do mini-batch: [%s]\" % (i+1, outputPrecision5))\n",
        "      log(\"\\tSaida esperada para o exemplo %d do mini-batch: [%s]\" % (i+1, expectedPrecision5))\n",
        "\n",
        "      Ji = sum([(-y * (math.log(f))) - ((1 - y)*(math.log(1 - f))) for y, f in zip(d[\"expected\"], d[\"results\"])])\n",
        "      J += Ji\n",
        "\n",
        "      log(\"\\tJ do exemplo %d do mini-batch: %.3f\\n\" % (i+1, Ji))\n",
        "\n",
        "\n",
        "    J = J / len(instances)\n",
        "\n",
        "    S = 0\n",
        "\n",
        "    for k, layer in enumerate(self.layers):\n",
        "      for ni, nn in enumerate(self.layers[k].neurons):\n",
        "        for i in range(1, len(nn.weights)):\n",
        "          S += nn.weights[i] ** 2\n",
        "\n",
        "    S = ( self.regularizationFactor / (2 * len(instances))) * S\n",
        "\n",
        "    totalJ = J + S\n",
        "\n",
        "    log(\"J total do mini-batch (com regularizacao): %.5f\\n\" % (totalJ))\n",
        "    return totalJ\n",
        "    \n",
        "  def backPropagation2(self, instances, J):\n",
        "    log(\"Rodando backpropagation\")\n",
        "\n",
        "    all_gradients = []  \n",
        "    for i, d in enumerate(instances):\n",
        "      log(\"\\tCalculando gradientes com base no exemplo %d:\" % (i+1))\n",
        "      instance_gradients = []\n",
        "\n",
        "      # Calculate delta for each neuron\n",
        "      for j in reversed(range(len(self.layers))):\n",
        "        deltas = []\n",
        "\n",
        "        if j == len(self.layers)-1:\n",
        "          # Calculate delta for last layer\n",
        "          deltas = d['results'] - d['expected']\n",
        "        else:\n",
        "          # Calculate delta for hidden layers\n",
        "          for ni, nn in enumerate(self.layers[j].neurons):\n",
        "            partial_deltas = []\n",
        "            for nj in self.layers[j+1].neurons: # for each neuron in next layer\n",
        "              # ni+1 is used to ignore bias, since weights[0] is the weight related to bias\n",
        "              delta_partial_result = nj.getDelta() * nj.weights[ni+1];\n",
        "              partial_deltas.append(delta_partial_result)\n",
        "            deltas.append(sum(partial_deltas)* self.derivativeFunction(d[\"activations\"][j][ni]))\n",
        "\n",
        "        for n in range(len(self.layers[j].neurons)):\n",
        "          self.layers[j].neurons[n].setDelta(deltas[n]) # TODO faz sentido salvar aqui??? na real, isso ta sendo usado?\n",
        "\n",
        "        log(\"\\t\\tdelta%d: [%s]\" % (j+2, printFloatPrecision5(deltas)))\n",
        "\n",
        "      #calcular gradiente dos thetas\n",
        "      for j in reversed(range(-1, len(self.layers)-1)):\n",
        "        weights = []\n",
        "        delta = np.array([])\n",
        "        activation = np.array([1])\n",
        "\n",
        "        if j == -1: # first layer\n",
        "          for n in range(len(self.layers[j+1].neurons)):\n",
        "            weights.append([self.layers[j+1].neurons[n].weights])\n",
        "            delta = np.append(delta, self.layers[j+1].neurons[n].delta)\n",
        "\n",
        "          activation = np.append(activation, d['attributes']) \n",
        "\n",
        "        else:\n",
        "          for n in range(len(self.layers[j].neurons)):\n",
        "            activation = np.append(activation, d[\"activations\"][j][n])\n",
        "\n",
        "          for n in range(len(self.layers[j+1].neurons)):\n",
        "            weights.append([self.layers[j+1].neurons[n].weights])\n",
        "            delta = np.append(delta, self.layers[j+1].neurons[n].delta)\n",
        "\n",
        "\n",
        "        activation = activation.reshape(activation.shape[0],-1)\n",
        "        delta = delta.reshape(delta.shape[0],-1)\n",
        "        weights = np.array(weights)\n",
        "\n",
        "        gradient = delta.dot(activation.T)\n",
        "\n",
        "        instance_gradients.append(gradient)\n",
        "\n",
        "        log(\"\\t\\tGradientes de Theta%d com base no exemplo %d:\" % (j+2, i+1))\n",
        "        log(twoDimensionPrintFloatPrecision5(gradient, \"\\t\\t\\t\"))\n",
        "\n",
        "      all_gradients.append(instance_gradients)  \n",
        "      \n",
        "     \n",
        "    log(\"\\tDataset completo (ou mini-batch) processado. Calculando gradientes regularizados\")\n",
        "\n",
        "    finalD = []\n",
        "\n",
        "    for ri, trow in enumerate(all_gradients[0]):\n",
        "      weights_wo_bias = []\n",
        "      for n in reversed(range(len(self.layers[len(self.layers)-ri-1].neurons))):\n",
        "        weights_wo_bias.append([0] + self.layers[len(self.layers)-ri-1].neurons[n].weights[1:])\n",
        "\n",
        "      P = np.array(list(reversed(weights_wo_bias))) * self.regularizationFactor\n",
        "\n",
        "      D = np.zeros((trow.shape[0], trow.shape[1]))\n",
        "\n",
        "      for rj in all_gradients:\n",
        "        D += rj[ri]\n",
        "\n",
        "      finalD.append((np.array(D) + P) / len(instances))\n",
        "\n",
        "    for i in range(len(self.layers)):\n",
        "      log(\"\\t\\tGradientes finais para Theta%d (com regularizacao):\" % (i+1))\n",
        "      log(twoDimensionPrintFloatPrecision5(finalD[len(finalD)-1-i], \"\\t\\t\\t\"))\n",
        "\n",
        "    self.updateWeights(list(reversed(finalD)), J) \n",
        "    \n",
        "  def miniBatchRun(self, dataset, iterations, minibatchK):\n",
        "    log(\"MINI BATCH RUN\")\n",
        "    print(\"RODANDO %d ITERAÇÕES:\" % iterations),\n",
        "    for i in range(iterations):\n",
        "      if (i+25) % 25 == 0:\n",
        "        print(\"%d ... \" % i, end=\"\")\n",
        "      for mb in range(math.ceil(len(dataset.instances) / minibatchK)):\n",
        "        currentMinibatchInstances = dataset.instances[mb*minibatchK:(mb+1)*minibatchK]\n",
        "        J = self.calculateNetworkError2(currentMinibatchInstances)\n",
        "        log(\"\\tDataset completo do mini-batch #%d processado. Calculando gradientes regularizados\" % mb)\n",
        "        self.backPropagation2(currentMinibatchInstances, J)\n",
        "      if (i+25) % 25 == 0:\n",
        "        print(\"J = %f \" % J)\n",
        "        \n",
        "  def verifyGradients(self, epsilon):\n",
        "    print(\"Rodando verificacao numerica de gradientes (epsilon = %f)\" % epsilon)\n",
        "    for i in range(len(self.layers)):\n",
        "      print(\"\\tGradiente numerico de Theta%d: TODO\" % (i+1))\n",
        "\n",
        "  def verifyGradientsCorretude(self):\n",
        "    print(\"Verificando corretude dos gradientes com base nos gradientes numericos:\")\n",
        "    for i in range(len(self.layers)):\n",
        "      print(\"\\tErro entre gradiente via backprop e gradiente numerico para Theta%d: TODO\" % (i+1))\n",
        "      \n",
        "  def classifyInstances(self, testSet):\n",
        "    results_all = []\n",
        "    for i, instance in enumerate(testSet):\n",
        "\n",
        "      inputPrecision5 = printFloatPrecision5(instance['attributes'])\n",
        "      expectedPrecision5 = printFloatPrecision5(instance['expected'])\n",
        "\n",
        "      log(\"\\tPropagando entrada de teste [%s]\" % inputPrecision5)\n",
        "\n",
        "      input = np.array([1] + instance['attributes']) # [1] is for bias\n",
        "\n",
        "      all_activations = []\n",
        "\n",
        "      for k, layer in enumerate(self.layers):\n",
        "        layer_activations =[]\n",
        "        prevInput = np.array([1])\n",
        "        results = []\n",
        "        for neuron in layer.neurons:\n",
        "          weights = np.array(neuron.weights)\n",
        "          result = weights.T.dot(input)\n",
        "          activation = self.activationFunction(result)\n",
        "          layer_activations.append(activation)\n",
        "          results.append(result)\n",
        "          prevInput = np.append(prevInput, activation)        \n",
        "\n",
        "        input = prevInput\n",
        "\n",
        "        all_activations.append(layer_activations)\n",
        "\n",
        "      instance[\"results\"] = np.round(input[1:], 5)\n",
        "      instance[\"activations\"] = all_activations\n",
        "\n",
        "      outputPrecision5 = printFloatPrecision5(input[1:]) # ignores first element (bias)\n",
        "      log(\"\\tSaida predita para o teste %d: [%s]\" % (i+1, outputPrecision5))\n",
        "      log(\"\\tSaida esperada para o teste %d: [%s]\\n\" % (i+1, expectedPrecision5))\n",
        "      \n",
        "      results_all.append(list(np.round(input[1:], 5)))\n",
        "    return results_all\n",
        "\n",
        "class TrainOrTestSet:\n",
        "  instances = []\n",
        "\n",
        "  def __init__(self):\n",
        "    self.instances = []\n",
        "\n",
        "  def append(self, instance):\n",
        "    self.instances.append(instance)\n",
        "    \n",
        "  def __str__(self):\n",
        "    msg = \"Conjunto de treinamento\\n\"\n",
        "    for i, instance in enumerate(self.instances):\n",
        "      msg += \"\\tExemplo %d\\n\\t\\tx: [%s]\\n\\t\\ty: [%s]\\n\" % (i+1, printFloatPrecision5(instance[\"attributes\"]), printFloatPrecision5(instance[\"expected\"]))\n",
        "    return msg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NStB7AuLcbgP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def createNetwork(networkFilename, initialWeightsFilename, inputSize, alpha):\n",
        "  regularizationFactor = 0\n",
        "  neuronsPerLayer = []\n",
        "  initialWeights = []\n",
        "\n",
        "  with open(networkFilename) as f:\n",
        "    line = f.readline()\n",
        "    cnt = 1\n",
        "    while line:\n",
        "\n",
        "      if cnt == 1:\n",
        "        regularizationFactor = float(line)\n",
        "      else:\n",
        "        neuronsPerLayer.append(int(line))\n",
        "\n",
        "      line = f.readline()\n",
        "      cnt += 1\n",
        "\n",
        "  with open(initialWeightsFilename) as f:\n",
        "    line = f.readline()\n",
        "    cnt = 1\n",
        "    while line:\n",
        "\n",
        "      splitLine = re.split(r';', line)\n",
        "\n",
        "      layerInitialWeights = []\n",
        "      for i in splitLine:\n",
        "        layerInitialWeights.append([float(w) for w in re.findall(r'\\d+\\.\\d+', i)])\n",
        "\n",
        "      initialWeights.append(layerInitialWeights)\n",
        "\n",
        "      line = f.readline()\n",
        "      cnt += 1\n",
        "  \n",
        "  network = Network(regularizationFactor, initialWeights, inputSize, alpha) \n",
        "  \n",
        "  return network\n",
        "\n",
        "def createTrainSet(datasetFilename):\n",
        "  trainSet = TrainOrTestSet()\n",
        "  with open(datasetFilename) as f:\n",
        "    \n",
        "    line = f.readline()\n",
        "    cnt = 1\n",
        "    \n",
        "    while line:\n",
        "      instance = {}\n",
        "      \n",
        "      splitLine = re.split(r';', line)\n",
        "      \n",
        "      instance = {}\n",
        "      instance['attributes'] = [float(a) for a in re.findall(r'\\d+\\.\\d+', splitLine[0])]\n",
        "      instance['expected'] = [float(a) for a in re.findall(r'\\d+\\.\\d+', splitLine[1])]\n",
        "      \n",
        "      trainSet.append(instance)\n",
        "      \n",
        "      line = f.readline()\n",
        "      cnt += 1\n",
        "      \n",
        "  return trainSet\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "er2oN1Ls2iL4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def randomWeight():\n",
        "  value = 0.0\n",
        "  while value == 0.0:\n",
        "    value = np.random.normal(0.0, 0.15) # values close to 0.0\n",
        "  return value\n",
        "\n",
        "def generateRandomWeights(neuronsPerLayer):\n",
        "  weights = []\n",
        "  \n",
        "  for i, layer in enumerate(neuronsPerLayer):\n",
        "    if i >= 1:\n",
        "      weights.append([[randomWeight() for j in range(neuronsPerLayer[i-1] + 1)] for k in range(neuronsPerLayer[i])])\n",
        "  return weights\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WYzTzEAsSAwg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def runPredefinedDataset(datasetName):\n",
        "  \"\"\"\n",
        "  dataset: {diabetes, ionosphere, cancer, wine}\n",
        "  \"\"\"\n",
        "  \n",
        "  global dataset, np_original_dataset, original_dataset, EXPECTED_COLUMN, possibleClasses\n",
        "    \n",
        "  if datasetName == \"diabetes\":\n",
        "    openFile(\"diabetes.csv\", ',')\n",
        "        \n",
        "    for d in original_dataset:\n",
        "      if d[-1] == '0':\n",
        "        d[-1] = 0.0\n",
        "      else: # 1\n",
        "        d[-1] = 1.0\n",
        "    \n",
        "    np_original_dataset = np.array(original_dataset).astype(np.float)\n",
        "    dataset = normalize_data(np.array(np_original_dataset).astype(np.float))\n",
        "    possibleClasses = generatePossibleClasses(original_dataset)\n",
        "    \n",
        "    numberInputs = len(dataset[1]) - 1\n",
        "    \n",
        "    #generateFoldsAndTest(numberInputs, [numberInputs, 2, 1], 0.05, 0.1, 20, 700)\n",
        "    generateFoldsAndTest(numberInputs, [numberInputs, 4, 1], 0.05, 0.1, 20, 700)\n",
        "    #generateFoldsAndTest(numberInputs, [numberInputs, 8, 1], 0.05, 0.1, 20, 700)\n",
        "\n",
        "  elif datasetName == \"wine\":\n",
        "    openFile(\"wine_with_names.csv\", ',')\n",
        "    \n",
        "    for d in original_dataset:\n",
        "      if d[-1] == '1':\n",
        "        d[-1] = 0.0\n",
        "      elif d[-1] == '2':\n",
        "        d[-1] = 0.5\n",
        "      else: # 3\n",
        "        d[-1] = 1.0\n",
        "    \n",
        "    np_original_dataset = np.array(original_dataset).astype(np.float)\n",
        "    dataset = normalize_data(np.array(np_original_dataset).astype(np.float))\n",
        "    possibleClasses = generatePossibleClasses(original_dataset)\n",
        "\n",
        "    numberInputs = len(dataset[1]) - 1\n",
        "\n",
        "    generateFoldsAndTest(numberInputs, [numberInputs, 5, 1], 0.05, 0.0, 20, 800)\n",
        "    #generateFoldsAndTest(numberInputs, [numberInputs, 10, 1], 0.05, 0.0, 20, 800)\n",
        "    #generateFoldsAndTest(numberInputs, [numberInputs, 15, 1], 0.05, 0.0, 20, 800)\n",
        "    #generateFoldsAndTest(numberInputs, [numberInputs, 4, 2, 1], 0.05, 0.0, 20, 800)\n",
        "\n",
        "  elif datasetName == \"ionosphere\":\n",
        "    \n",
        "    openFile(\"ionosphere_with_names.csv\", ',')\n",
        "    \n",
        "    for d in original_dataset:\n",
        "      if d[-1] == 'g':\n",
        "        d[-1] = 0.0\n",
        "      else: # 'b'\n",
        "        d[-1] = 1.0\n",
        "    np_original_dataset = np.array(original_dataset).astype(np.float)\n",
        "    dataset = normalize_data(np.array(np_original_dataset).astype(np.float))\n",
        "    possibleClasses = generatePossibleClasses(original_dataset)\n",
        "    \n",
        "    numberInputs = len(dataset[1]) - 1\n",
        "    \n",
        "    generateFoldsAndTest(numberInputs, [numberInputs, 4, 1], 0.05, 0.1, 20, 700) \n",
        "    #generateFoldsAndTest(numberInputs, [numberInputs, 6, 1], 0.05, 0.1, 20, 700) \n",
        "    #generateFoldsAndTest(numberInputs, [numberInputs, 8, 1], 0.05, 0.1, 20, 700) \n",
        "    #generateFoldsAndTest(numberInputs, [numberInputs, 4, 2, 1], 0.05, 0.1, 20, 700) \n",
        "    \n",
        "    \n",
        "  elif datasetName == \"cancer\":\n",
        "    \n",
        "    openFile(\"wdbc_with_names.csv\", ',')\n",
        "    \n",
        "    for d in original_dataset:\n",
        "      if d[-1] == 'B':\n",
        "        d[-1] = 0.0\n",
        "      else: # 'M'\n",
        "        d[-1] = 1.0\n",
        "    np_original_dataset = np.array(original_dataset).astype(np.float)\n",
        "    dataset = normalize_data(np.array(np_original_dataset).astype(np.float))\n",
        "    possibleClasses = generatePossibleClasses(original_dataset)\n",
        "    \n",
        "    numberInputs = len(dataset[1]) - 1\n",
        "  \n",
        "    generateFoldsAndTest(numberInputs, [numberInputs, 5, 1], 0.05, 0.1, 20, 700)\n",
        "    #generateFoldsAndTest(numberInputs, [numberInputs, 10, 1], 0.05, 0.1, 20, 700)\n",
        "    #generateFoldsAndTest(numberInputs, [numberInputs, 15, 1], 0.05, 0.1, 20, 700)\n",
        "    \n",
        "  \n",
        "  else:\n",
        "    print(\"Invalid dataset. Available options are: diabetes; wine; ionosphere; cancer.\")\n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gR07VLSgKTQw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def fold_i_of_k(dataset, i, k):\n",
        "    n = len(dataset)\n",
        "    return dataset[n*(i-1)//k:n*i//k]\n",
        "\n",
        "def calculateAccuracyAndF1(testFold, results, possibleClassesLen):    \n",
        "  if possibleClassesLen == 2:\n",
        "    incorrect = 0\n",
        "    fp = fn = vp = vn = 0\n",
        "    range_size = 0.5\n",
        "\n",
        "    for i in range(len(testFold)):\n",
        "      if math.fabs(testFold[i][-1] - results[i][0]) >= range_size:\n",
        "          incorrect += 1 # For acurracy\n",
        "          if results[i][0] < range_size:\n",
        "              fn += 1\n",
        "          elif results[i][0] >= range_size:\n",
        "              fp += 1\n",
        "      else:\n",
        "          if results[i][0] < range_size:\n",
        "              vn += 1\n",
        "          elif results[i][0] >= range_size:\n",
        "              vp += 1\n",
        "\n",
        "    print (\"vp: \" + str(vp) + \"  vn: \" + str(vn) + \" fp: \" + str(fp) + \" fn: \" + str(fn))\n",
        "\n",
        "    rev =  vp / float(vp + fn)\n",
        "    prec = vp / float(vp + fp)\n",
        "\n",
        "    f1 = 2 * (prec * rev / float(prec + rev))\n",
        "    \n",
        "    return (1 - (incorrect/float(len(testFold)))), f1\n",
        "    \n",
        "  elif possibleClassesLen == 3:\n",
        "    range_size = 1/3.0\n",
        "\n",
        "    incorrect = 0\n",
        "    revs = []\n",
        "    precs = []\n",
        "    f1s_sum = 0\n",
        "\n",
        "    for j in range(3):\n",
        "      fp = fn = vp = vn = 0\n",
        "      for i in range(len(testFold)):\n",
        "        result = results[i][0]\n",
        "\n",
        "        if j*range_size < result and result <= (j+1)*range_size:\n",
        "          if j*range_size <= testFold[i][-1] and testFold[i][-1] <= (j+1)*range_size:\n",
        "            vp += 1\n",
        "          else:\n",
        "            fp += 1\n",
        "            incorrect += 1 # For acurracy\n",
        "\n",
        "        else:\n",
        "          if j*range_size <= testFold[i][-1] and testFold[i][-1] <= (j+1)*range_size:\n",
        "            fn += 1\n",
        "            incorrect += 1 # For acurracy\n",
        "          else:\n",
        "            vn += 1\n",
        "\n",
        "\n",
        "      print (\"vp: \" + str(vp) + \"  vn: \" + str(vn) + \" fp: \" + str(fp) + \" fn: \" + str(fn))\n",
        "\n",
        "      rev = 0\n",
        "      if vp + fn != 0:\n",
        "        rev =  vp / float(vp + fn)\n",
        "\n",
        "      prec = 0\n",
        "      if vp + fp != 0:\n",
        "        prec = vp / float(vp + fp)\n",
        "\n",
        "      if (prec == 0 or rev == 0):\n",
        "        f1 = 0\n",
        "      else:\n",
        "        f1 = (2 * (prec * rev / float(prec + rev)) )\n",
        "      f1s_sum += f1\n",
        "\n",
        "    return (1 - (incorrect/float(len(testFold)))/3), f1s_sum/3\n",
        "\n",
        "def generateFoldsAndTest(numberInputs, networkFormat, alpha, regularizationFactor, minibatchK, iterations):\n",
        "  \n",
        "  dataset_copy = copy.copy(dataset)\n",
        "  np.random.shuffle(dataset_copy)\n",
        "  \n",
        "  outcomes = { d:[] for i,d in enumerate(possibleClasses)}\n",
        "  \n",
        "  for i in dataset_copy:\n",
        "    outcomes[((i[-1]))].append(i)\n",
        "  \n",
        "  folds_by_class = {}\n",
        "  for index, d in enumerate(possibleClasses):\n",
        "    folds_by_class[d] = [fold_i_of_k(outcomes[d], i+1, KFOLDS) for i in range(KFOLDS)]\n",
        "  \n",
        "  folds = [np.concatenate(tuple(folds_by_class[d][i] for d in possibleClasses), axis=0) for i in range(KFOLDS)]\n",
        "  \n",
        "  accuracy = [0 for i in range(KFOLDS)]\n",
        "  f1_score = [0 for i in range(KFOLDS)]\n",
        "\n",
        "  print(\"KFOLDS = %d \\t\" % KFOLDS)\n",
        "  \n",
        "  for i in range(KFOLDS):\n",
        "      minlen = len(dataset)\n",
        "      for v1 in folds_by_class.keys():\n",
        "        for v2 in folds_by_class[v1]:\n",
        "          minlen = min(minlen, len(v2))\n",
        "\n",
        "      # Concatenate\n",
        "      original_testing_fold = np.concatenate(tuple(folds_by_class[d][i][0:minlen-1] for d in possibleClasses), axis=0)\n",
        "\n",
        "      training_fold = None\n",
        "      for j in range(KFOLDS):\n",
        "          if (i != j):\n",
        "              if training_fold is None:\n",
        "                  training_fold = np.concatenate(tuple(folds_by_class[d][j][0:minlen-1] for d in possibleClasses), axis=0)\n",
        "              else:\n",
        "                  newarray = np.concatenate(tuple(folds_by_class[d][j][0:minlen-1] for d in possibleClasses), axis=0)\n",
        "                  training_fold = np.concatenate((training_fold, newarray), axis=0)\n",
        "\n",
        "      # Create network\n",
        "      initialWeights = generateRandomWeights(networkFormat)\n",
        "    \n",
        "      network = Network(regularizationFactor, initialWeights, numberInputs, alpha)\n",
        "      log(network)\n",
        "\n",
        "      # Train\n",
        "      trainingSet = TrainOrTestSet()\n",
        "      for instance in training_fold:\n",
        "        trainingSet.append({\"attributes\": instance[:-1].tolist(), \"expected\": [instance[-1].tolist()]})\n",
        "\n",
        "      network.miniBatchRun(trainingSet, iterations, minibatchK)\n",
        "\n",
        "      fold_results = []\n",
        "      testingSet = TrainOrTestSet()\n",
        "      for instance in original_testing_fold:\n",
        "        testingSet.append({\"attributes\": instance[:-1].tolist(), \"expected\": [instance[-1].tolist()]})\n",
        "\n",
        "      fold_results = network.classifyInstances(testingSet.instances)\n",
        "      #print(\"EXPECTED:\")\n",
        "      #print([x[\"expected\"] for x in testingSet.instances])\n",
        "      #print(\"FOLD RESULTS\")\n",
        "      #print(fold_results)\n",
        "                     \n",
        "      if len(possibleClasses) <= 3:\n",
        "        acc, f1 = calculateAccuracyAndF1(original_testing_fold, fold_results, len(possibleClasses))\n",
        "        accuracy[i] = acc\n",
        "        f1_score[i] = f1\n",
        "        print(\"FOLD #%d ->  acc:%f  f1:%f\" % (i+1, acc, f1))\n",
        "\n",
        "  if len(possibleClasses) <= 3:\n",
        "    accuracy_avg = np.average(accuracy)\n",
        "    accuracy_std = np.std(accuracy)\n",
        "    f1_avg = np.average(f1_score)\n",
        "    f1_std = np.std(f1_score)\n",
        "    print(\"Acurácia   -> \\tMédia: %.2f\\tDesvio Padrão: %.2f\" % (accuracy_avg, accuracy_std))\n",
        "    print(\"Escore F-1 -> \\tMédia: %.2f\\tDesvio Padrão: %.2f\" % (f1_avg, f1_std))\n",
        "    return [f1_avg, f1_std]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h9sa4rR_4X-M",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 12800
        },
        "outputId": "5ad9118e-b6bc-40c9-c2f1-8ca2e49491e1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1529553038303,
          "user_tz": 180,
          "elapsed": 247476,
          "user": {
            "displayName": "Augusto Bennemann",
            "photoUrl": "//lh4.googleusercontent.com/-uh1jffP4anU/AAAAAAAAAAI/AAAAAAAAA88/1TQ_-mFOf34/s50-c-k-no/photo.jpg",
            "userId": "110926773250512152064"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#runPredefinedDataset(\"diabetes\")\n",
        "runPredefinedDataset(\"wine\")\n",
        "#runPredefinedDataset(\"ionosphere\")\n",
        "#runPredefinedDataset(\"cancer\")\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attribute_index = -1\n",
            "{0.0: 59.0, 0.5: 71.0, 1.0: 48.0}\n",
            "{0.0: 0, 0.5: 1, 1.0: 2}\n",
            "KFOLDS = 10 \t\n",
            "Inicializando rede com a seguinte estrutura de neuronios por camadas: [13 5 1]\n",
            "RODANDO 800 ITERAÇÕES:\n",
            "0 ... J = 0.686450 \n",
            "25 ... J = 0.557149 \n",
            "50 ... J = 0.546971 \n",
            "75 ... J = 0.541990 \n",
            "100 ... J = 0.536349 \n",
            "125 ... J = 0.529210 \n",
            "150 ... J = 0.519883 \n",
            "175 ... J = 0.507631 \n",
            "200 ... J = 0.491726 \n",
            "225 ... J = 0.471573 \n",
            "250 ... J = 0.446959 \n",
            "275 ... J = 0.418216 \n",
            "300 ... J = 0.386354 \n",
            "325 ... J = 0.352825 \n",
            "350 ... J = 0.319200 \n",
            "375 ... J = 0.286856 \n",
            "400 ... J = 0.256752 \n",
            "425 ... J = 0.229426 \n",
            "450 ... J = 0.205046 \n",
            "475 ... J = 0.183562 \n",
            "500 ... J = 0.164769 \n",
            "525 ... J = 0.148384 \n",
            "550 ... J = 0.134126 \n",
            "575 ... J = 0.121716 \n",
            "600 ... J = 0.110898 \n",
            "625 ... J = 0.101446 \n",
            "650 ... J = 0.093168 \n",
            "675 ... J = 0.085896 \n",
            "700 ... J = 0.079476 \n",
            "725 ... J = 0.073797 \n",
            "750 ... J = 0.068761 \n",
            "775 ... J = 0.064261 \n",
            "EXPECTED:\n",
            "[[0.0], [0.0], [0.0], [0.5], [0.5], [0.5], [1.0], [1.0], [1.0]]\n",
            "FOLD RESULTS\n",
            "[[0.17671], [0.16835], [0.19241], [0.44142], [0.53768], [0.26793], [0.8929], [0.85851], [0.93222]]\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "VNn++\n",
            "VNn++\n",
            "FP++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "vp: 3  vn: 5 fp: 1 fn: 0\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VP++\n",
            "VP++\n",
            "FN++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "vp: 2  vn: 6 fp: 0 fn: 1\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "vp: 3  vn: 6 fp: 0 fn: 0\n",
            "FOLD #1 ->  acc:0.925926  f1:0.885714\n",
            "Inicializando rede com a seguinte estrutura de neuronios por camadas: [13 5 1]\n",
            "RODANDO 800 ITERAÇÕES:\n",
            "0 ... J = 0.750437 \n",
            "25 ... J = 0.568649 \n",
            "50 ... J = 0.554690 \n",
            "75 ... J = 0.544951 \n",
            "100 ... J = 0.533361 \n",
            "125 ... J = 0.518421 \n",
            "150 ... J = 0.498946 \n",
            "175 ... J = 0.474333 \n",
            "200 ... J = 0.444819 \n",
            "225 ... J = 0.411614 \n",
            "250 ... J = 0.376572 \n",
            "275 ... J = 0.341646 \n",
            "300 ... J = 0.308416 \n",
            "325 ... J = 0.277851 \n",
            "350 ... J = 0.250412 \n",
            "375 ... J = 0.226123 \n",
            "400 ... J = 0.204825 \n",
            "425 ... J = 0.186233 \n",
            "450 ... J = 0.170018 \n",
            "475 ... J = 0.155870 \n",
            "500 ... J = 0.143501 \n",
            "525 ... J = 0.132652 \n",
            "550 ... J = 0.123106 \n",
            "575 ... J = 0.114682 \n",
            "600 ... J = 0.107207 \n",
            "625 ... J = 0.100561 \n",
            "650 ... J = 0.094618 \n",
            "675 ... J = 0.089301 \n",
            "700 ... J = 0.084513 \n",
            "725 ... J = 0.080202 \n",
            "750 ... J = 0.076298 \n",
            "775 ... J = 0.072754 \n",
            "EXPECTED:\n",
            "[[0.0], [0.0], [0.0], [0.5], [0.5], [0.5], [1.0], [1.0], [1.0]]\n",
            "FOLD RESULTS\n",
            "[[0.19445], [0.25922], [0.18243], [0.47311], [0.30591], [0.73], [0.84046], [0.88547], [0.81869]]\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "VNn++\n",
            "FP++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "vp: 3  vn: 5 fp: 1 fn: 0\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VP++\n",
            "FN++\n",
            "FN++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "vp: 1  vn: 6 fp: 0 fn: 2\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "FP++\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "vp: 3  vn: 5 fp: 1 fn: 0\n",
            "FOLD #2 ->  acc:0.851852  f1:0.738095\n",
            "Inicializando rede com a seguinte estrutura de neuronios por camadas: [13 5 1]\n",
            "RODANDO 800 ITERAÇÕES:\n",
            "0 ... J = 0.814524 \n",
            "25 ... J = 0.547420 \n",
            "50 ... J = 0.530093 \n",
            "75 ... J = 0.521246 \n",
            "100 ... J = 0.510942 \n",
            "125 ... J = 0.498041 \n",
            "150 ... J = 0.481850 \n",
            "175 ... J = 0.461845 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200 ... J = 0.437839 \n",
            "225 ... J = 0.410031 \n",
            "250 ... J = 0.379184 \n",
            "275 ... J = 0.346456 \n",
            "300 ... J = 0.313219 \n",
            "325 ... J = 0.280812 \n",
            "350 ... J = 0.250296 \n",
            "375 ... J = 0.222331 \n",
            "400 ... J = 0.197281 \n",
            "425 ... J = 0.175175 \n",
            "450 ... J = 0.155870 \n",
            "475 ... J = 0.139124 \n",
            "500 ... J = 0.124645 \n",
            "525 ... J = 0.112128 \n",
            "550 ... J = 0.101313 \n",
            "575 ... J = 0.091940 \n",
            "600 ... J = 0.083795 \n",
            "625 ... J = 0.076708 \n",
            "650 ... J = 0.070498 \n",
            "675 ... J = 0.065051 \n",
            "700 ... J = 0.060249 \n",
            "725 ... J = 0.055999 \n",
            "750 ... J = 0.052231 \n",
            "775 ... J = 0.048875 \n",
            "EXPECTED:\n",
            "[[0.0], [0.0], [0.0], [0.5], [0.5], [0.5], [1.0], [1.0], [1.0]]\n",
            "FOLD RESULTS\n",
            "[[0.21155], [0.23317], [0.19033], [0.20044], [0.69486], [0.33378], [0.77631], [0.8318], [0.93054]]\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "FP++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "vp: 3  vn: 5 fp: 1 fn: 0\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "FN++\n",
            "FN++\n",
            "VP++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "vp: 1  vn: 6 fp: 0 fn: 2\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "FP++\n",
            "VNn++\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "vp: 3  vn: 5 fp: 1 fn: 0\n",
            "FOLD #3 ->  acc:0.851852  f1:0.738095\n",
            "Inicializando rede com a seguinte estrutura de neuronios por camadas: [13 5 1]\n",
            "RODANDO 800 ITERAÇÕES:\n",
            "0 ... J = 0.854161 \n",
            "25 ... J = 0.561979 \n",
            "50 ... J = 0.542110 \n",
            "75 ... J = 0.535289 \n",
            "100 ... J = 0.527277 \n",
            "125 ... J = 0.516257 \n",
            "150 ... J = 0.501123 \n",
            "175 ... J = 0.480976 \n",
            "200 ... J = 0.455296 \n",
            "225 ... J = 0.424388 \n",
            "250 ... J = 0.389464 \n",
            "275 ... J = 0.352541 \n",
            "300 ... J = 0.315739 \n",
            "325 ... J = 0.280826 \n",
            "350 ... J = 0.248961 \n",
            "375 ... J = 0.220659 \n",
            "400 ... J = 0.195966 \n",
            "425 ... J = 0.174663 \n",
            "450 ... J = 0.156385 \n",
            "475 ... J = 0.140723 \n",
            "500 ... J = 0.127299 \n",
            "525 ... J = 0.115770 \n",
            "550 ... J = 0.105838 \n",
            "575 ... J = 0.097227 \n",
            "600 ... J = 0.089739 \n",
            "625 ... J = 0.083197 \n",
            "650 ... J = 0.077464 \n",
            "675 ... J = 0.072399 \n",
            "700 ... J = 0.067915 \n",
            "725 ... J = 0.063931 \n",
            "750 ... J = 0.060366 \n",
            "775 ... J = 0.057184 \n",
            "EXPECTED:\n",
            "[[0.0], [0.0], [0.0], [0.5], [0.5], [0.5], [1.0], [1.0], [1.0]]\n",
            "FOLD RESULTS\n",
            "[[0.24589], [0.18648], [0.17475], [0.26645], [0.15615], [0.44403], [0.91284], [0.90092], [0.89593]]\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "FP++\n",
            "FP++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "vp: 3  vn: 4 fp: 2 fn: 0\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "FN++\n",
            "FN++\n",
            "VP++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "vp: 1  vn: 6 fp: 0 fn: 2\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "vp: 3  vn: 6 fp: 0 fn: 0\n",
            "FOLD #4 ->  acc:0.851852  f1:0.750000\n",
            "Inicializando rede com a seguinte estrutura de neuronios por camadas: [13 5 1]\n",
            "RODANDO 800 ITERAÇÕES:\n",
            "0 ... J = 0.593392 \n",
            "25 ... J = 0.559211 \n",
            "50 ... J = 0.552638 \n",
            "75 ... J = 0.546902 \n",
            "100 ... J = 0.539980 \n",
            "125 ... J = 0.530858 \n",
            "150 ... J = 0.518421 \n",
            "175 ... J = 0.501503 \n",
            "200 ... J = 0.479004 \n",
            "225 ... J = 0.450405 \n",
            "250 ... J = 0.416137 \n",
            "275 ... J = 0.377782 \n",
            "300 ... J = 0.337741 \n",
            "325 ... J = 0.298541 \n",
            "350 ... J = 0.262105 \n",
            "375 ... J = 0.229539 \n",
            "400 ... J = 0.201186 \n",
            "425 ... J = 0.176892 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "450 ... J = 0.156268 \n",
            "475 ... J = 0.138825 \n",
            "500 ... J = 0.124068 \n",
            "525 ... J = 0.111557 \n",
            "550 ... J = 0.100904 \n",
            "575 ... J = 0.091797 \n",
            "600 ... J = 0.083969 \n",
            "625 ... J = 0.077205 \n",
            "650 ... J = 0.071324 \n",
            "675 ... J = 0.066204 \n",
            "700 ... J = 0.061705 \n",
            "725 ... J = 0.057746 \n",
            "750 ... J = 0.054234 \n",
            "775 ... J = 0.051114 \n",
            "EXPECTED:\n",
            "[[0.0], [0.0], [0.0], [0.5], [0.5], [0.5], [1.0], [1.0], [1.0]]\n",
            "FOLD RESULTS\n",
            "[[0.119], [0.15268], [0.31111], [0.58207], [0.43932], [0.46303], [0.87916], [0.88424], [0.84335]]\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "vp: 3  vn: 6 fp: 0 fn: 0\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "vp: 3  vn: 6 fp: 0 fn: 0\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "vp: 3  vn: 6 fp: 0 fn: 0\n",
            "FOLD #5 ->  acc:1.000000  f1:1.000000\n",
            "Inicializando rede com a seguinte estrutura de neuronios por camadas: [13 5 1]\n",
            "RODANDO 800 ITERAÇÕES:\n",
            "0 ... J = 0.722885 \n",
            "25 ... J = 0.554029 \n",
            "50 ... J = 0.542213 \n",
            "75 ... J = 0.536930 \n",
            "100 ... J = 0.530416 \n",
            "125 ... J = 0.521516 \n",
            "150 ... J = 0.509393 \n",
            "175 ... J = 0.493133 \n",
            "200 ... J = 0.471909 \n",
            "225 ... J = 0.445350 \n",
            "250 ... J = 0.413805 \n",
            "275 ... J = 0.378570 \n",
            "300 ... J = 0.341603 \n",
            "325 ... J = 0.305018 \n",
            "350 ... J = 0.270537 \n",
            "375 ... J = 0.239248 \n",
            "400 ... J = 0.211586 \n",
            "425 ... J = 0.187559 \n",
            "450 ... J = 0.166905 \n",
            "475 ... J = 0.149220 \n",
            "500 ... J = 0.134103 \n",
            "525 ... J = 0.121174 \n",
            "550 ... J = 0.110083 \n",
            "575 ... J = 0.100539 \n",
            "600 ... J = 0.092269 \n",
            "625 ... J = 0.085100 \n",
            "650 ... J = 0.078838 \n",
            "675 ... J = 0.073334 \n",
            "700 ... J = 0.068504 \n",
            "725 ... J = 0.064219 \n",
            "750 ... J = 0.060419 \n",
            "775 ... J = 0.057025 \n",
            "EXPECTED:\n",
            "[[0.0], [0.0], [0.0], [0.5], [0.5], [0.5], [1.0], [1.0], [1.0]]\n",
            "FOLD RESULTS\n",
            "[[0.14487], [0.18272], [0.19664], [0.25291], [0.33464], [0.41877], [0.84316], [0.90622], [0.89363]]\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "FP++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "vp: 3  vn: 5 fp: 1 fn: 0\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "FN++\n",
            "VP++\n",
            "VP++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "vp: 2  vn: 6 fp: 0 fn: 1\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "vp: 3  vn: 6 fp: 0 fn: 0\n",
            "FOLD #6 ->  acc:0.925926  f1:0.885714\n",
            "Inicializando rede com a seguinte estrutura de neuronios por camadas: [13 5 1]\n",
            "RODANDO 800 ITERAÇÕES:\n",
            "0 ... J = 0.604898 \n",
            "25 ... J = 0.555945 \n",
            "50 ... J = 0.548822 \n",
            "75 ... J = 0.542041 \n",
            "100 ... J = 0.533259 \n",
            "125 ... J = 0.521566 \n",
            "150 ... J = 0.506054 \n",
            "175 ... J = 0.486035 \n",
            "200 ... J = 0.461258 \n",
            "225 ... J = 0.432184 \n",
            "250 ... J = 0.400030 \n",
            "275 ... J = 0.366437 \n",
            "300 ... J = 0.333098 \n",
            "325 ... J = 0.301362 \n",
            "350 ... J = 0.272071 \n",
            "375 ... J = 0.245632 \n",
            "400 ... J = 0.222107 \n",
            "425 ... J = 0.201370 \n",
            "450 ... J = 0.183166 \n",
            "475 ... J = 0.167224 \n",
            "500 ... J = 0.153268 \n",
            "525 ... J = 0.141011 \n",
            "550 ... J = 0.130234 \n",
            "575 ... J = 0.120734 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "600 ... J = 0.112318 \n",
            "625 ... J = 0.104850 \n",
            "650 ... J = 0.098197 \n",
            "675 ... J = 0.092258 \n",
            "700 ... J = 0.086931 \n",
            "725 ... J = 0.082132 \n",
            "750 ... J = 0.077799 \n",
            "775 ... J = 0.073883 \n",
            "EXPECTED:\n",
            "[[0.0], [0.0], [0.0], [0.5], [0.5], [0.5], [1.0], [1.0], [1.0]]\n",
            "FOLD RESULTS\n",
            "[[0.17251], [0.21892], [0.12912], [0.2009], [0.43327], [0.58845], [0.88953], [0.89511], [0.85559]]\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "FP++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "vp: 3  vn: 5 fp: 1 fn: 0\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "FN++\n",
            "VP++\n",
            "VP++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "vp: 2  vn: 6 fp: 0 fn: 1\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "vp: 3  vn: 6 fp: 0 fn: 0\n",
            "FOLD #7 ->  acc:0.925926  f1:0.885714\n",
            "Inicializando rede com a seguinte estrutura de neuronios por camadas: [13 5 1]\n",
            "RODANDO 800 ITERAÇÕES:\n",
            "0 ... J = 0.622335 \n",
            "25 ... J = 0.557865 \n",
            "50 ... J = 0.549255 \n",
            "75 ... J = 0.541886 \n",
            "100 ... J = 0.532117 \n",
            "125 ... J = 0.518656 \n",
            "150 ... J = 0.500314 \n",
            "175 ... J = 0.476134 \n",
            "200 ... J = 0.445897 \n",
            "225 ... J = 0.410422 \n",
            "250 ... J = 0.371629 \n",
            "275 ... J = 0.331996 \n",
            "300 ... J = 0.293821 \n",
            "325 ... J = 0.258745 \n",
            "350 ... J = 0.227591 \n",
            "375 ... J = 0.200538 \n",
            "400 ... J = 0.177370 \n",
            "425 ... J = 0.157648 \n",
            "450 ... J = 0.140919 \n",
            "475 ... J = 0.126709 \n",
            "500 ... J = 0.114603 \n",
            "525 ... J = 0.104250 \n",
            "550 ... J = 0.095355 \n",
            "575 ... J = 0.087673 \n",
            "600 ... J = 0.080993 \n",
            "625 ... J = 0.075176 \n",
            "650 ... J = 0.070068 \n",
            "675 ... J = 0.065574 \n",
            "700 ... J = 0.061588 \n",
            "725 ... J = 0.058053 \n",
            "750 ... J = 0.054889 \n",
            "775 ... J = 0.052062 \n",
            "EXPECTED:\n",
            "[[0.0], [0.0], [0.0], [0.5], [0.5], [0.5], [1.0], [1.0], [1.0]]\n",
            "FOLD RESULTS\n",
            "[[0.11254], [0.24827], [0.23629], [0.32211], [0.45546], [0.72747], [0.92383], [0.87697], [0.79788]]\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "FP++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "vp: 3  vn: 5 fp: 1 fn: 0\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "FN++\n",
            "VP++\n",
            "FN++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "vp: 1  vn: 6 fp: 0 fn: 2\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "FP++\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "vp: 3  vn: 5 fp: 1 fn: 0\n",
            "FOLD #8 ->  acc:0.851852  f1:0.738095\n",
            "Inicializando rede com a seguinte estrutura de neuronios por camadas: [13 5 1]\n",
            "RODANDO 800 ITERAÇÕES:\n",
            "0 ... J = 0.574049 \n",
            "25 ... J = 0.564015 \n",
            "50 ... J = 0.561119 \n",
            "75 ... J = 0.558914 \n",
            "100 ... J = 0.556817 \n",
            "125 ... J = 0.554569 \n",
            "150 ... J = 0.551839 \n",
            "175 ... J = 0.548251 \n",
            "200 ... J = 0.543349 \n",
            "225 ... J = 0.536485 \n",
            "250 ... J = 0.526853 \n",
            "275 ... J = 0.513479 \n",
            "300 ... J = 0.495428 \n",
            "325 ... J = 0.472022 \n",
            "350 ... J = 0.443198 \n",
            "375 ... J = 0.409805 \n",
            "400 ... J = 0.373501 \n",
            "425 ... J = 0.336368 \n",
            "450 ... J = 0.300349 \n",
            "475 ... J = 0.266847 \n",
            "500 ... J = 0.236659 \n",
            "525 ... J = 0.210030 \n",
            "550 ... J = 0.186896 \n",
            "575 ... J = 0.166929 \n",
            "600 ... J = 0.149789 \n",
            "625 ... J = 0.135064 \n",
            "650 ... J = 0.122405 \n",
            "675 ... J = 0.111502 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "700 ... J = 0.102066 \n",
            "725 ... J = 0.093871 \n",
            "750 ... J = 0.086724 \n",
            "775 ... J = 0.080462 \n",
            "EXPECTED:\n",
            "[[0.0], [0.0], [0.0], [0.5], [0.5], [0.5], [1.0], [1.0], [1.0]]\n",
            "FOLD RESULTS\n",
            "[[0.17235], [0.27861], [0.16359], [0.27919], [0.41579], [0.49621], [0.81885], [0.85588], [0.85092]]\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "FP++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "vp: 3  vn: 5 fp: 1 fn: 0\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "FN++\n",
            "VP++\n",
            "VP++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "vp: 2  vn: 6 fp: 0 fn: 1\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "vp: 3  vn: 6 fp: 0 fn: 0\n",
            "FOLD #9 ->  acc:0.925926  f1:0.885714\n",
            "Inicializando rede com a seguinte estrutura de neuronios por camadas: [13 5 1]\n",
            "RODANDO 800 ITERAÇÕES:\n",
            "0 ... J = 0.748153 \n",
            "25 ... J = 0.550398 \n",
            "50 ... J = 0.539311 \n",
            "75 ... J = 0.533736 \n",
            "100 ... J = 0.527158 \n",
            "125 ... J = 0.518992 \n",
            "150 ... J = 0.508828 \n",
            "175 ... J = 0.496348 \n",
            "200 ... J = 0.481332 \n",
            "225 ... J = 0.463735 \n",
            "250 ... J = 0.443728 \n",
            "275 ... J = 0.421793 \n",
            "300 ... J = 0.398524 \n",
            "325 ... J = 0.374664 \n",
            "350 ... J = 0.350892 \n",
            "375 ... J = 0.327782 \n",
            "400 ... J = 0.305765 \n",
            "425 ... J = 0.285085 \n",
            "450 ... J = 0.265881 \n",
            "475 ... J = 0.248205 \n",
            "500 ... J = 0.232020 \n",
            "525 ... J = 0.217248 \n",
            "550 ... J = 0.203807 \n",
            "575 ... J = 0.191572 \n",
            "600 ... J = 0.180431 \n",
            "625 ... J = 0.170278 \n",
            "650 ... J = 0.161026 \n",
            "675 ... J = 0.152580 \n",
            "700 ... J = 0.144852 \n",
            "725 ... J = 0.137769 \n",
            "750 ... J = 0.131260 \n",
            "775 ... J = 0.125268 \n",
            "EXPECTED:\n",
            "[[0.0], [0.0], [0.0], [0.5], [0.5], [0.5], [1.0], [1.0], [1.0]]\n",
            "FOLD RESULTS\n",
            "[[0.23325], [0.19184], [0.23787], [0.81597], [0.74203], [0.32788], [0.88598], [0.88025], [0.92499]]\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "VNn++\n",
            "VNn++\n",
            "FP++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "vp: 3  vn: 5 fp: 1 fn: 0\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "FN++\n",
            "FN++\n",
            "FN++\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "vp: 0  vn: 6 fp: 0 fn: 3\n",
            "VNn++\n",
            "VNn++\n",
            "VNn++\n",
            "FP++\n",
            "FP++\n",
            "VNn++\n",
            "VP++\n",
            "VP++\n",
            "VP++\n",
            "vp: 3  vn: 4 fp: 2 fn: 0\n",
            "FOLD #10 ->  acc:0.777778  f1:0.535714\n",
            "Acurácia   -> \tMédia: 0.89\tDesvio Padrão: 0.06\n",
            "Escore F-1 -> \tMédia: 0.80\tDesvio Padrão: 0.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g-Wqz6rnuQ2D",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5jNYEnFpuXft",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "49-kaYVo2Hs_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}